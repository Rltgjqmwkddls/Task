{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd35c01",
   "metadata": {},
   "source": [
    "### AI 허브에서 차량 번호판 데이터를 받아와서 구현\n",
    "### Training데이터에서 원천데이터와 라벨링데이터를 다운로드 받아서 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782b9d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.18.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.4.1-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (10.3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: paddlepaddle in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: paddleocr in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchaudio-2.4.0-cp310-cp310-win_amd64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.3.1-cp310-cp310-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddlepaddle) (0.27.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddlepaddle) (5.1.1)\n",
      "Requirement already satisfied: astor in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddlepaddle) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddlepaddle) (3.3.0)\n",
      "Requirement already satisfied: protobuf<=3.20.2,>=3.1.0 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddlepaddle) (3.20.2)\n",
      "Requirement already satisfied: shapely in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (2.0.5)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (0.24.0)\n",
      "Requirement already satisfied: imgaug in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (0.4.0)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (1.3.0.post5)\n",
      "Requirement already satisfied: lmdb in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (1.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (4.66.4)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (3.9.6)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (4.10.0.84)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (4.10.0.84)\n",
      "Requirement already satisfied: cython in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (3.0.11)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (6.0.1)\n",
      "Requirement already satisfied: python-docx in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (1.1.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (4.12.3)\n",
      "Requirement already satisfied: fire>=0.3.0 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (0.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from paddleocr) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fire>=0.3.0->paddleocr) (1.16.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fire>=0.3.0->paddleocr) (2.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4->paddleocr) (2.5)\n",
      "Requirement already satisfied: anyio in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->paddlepaddle) (4.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->paddlepaddle) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->paddlepaddle) (1.0.4)\n",
      "Requirement already satisfied: idna in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->paddlepaddle) (3.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx->paddlepaddle) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx->paddlepaddle) (0.14.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imgaug->paddleocr) (2.35.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image->paddleocr) (2024.8.10)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image->paddleocr) (0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-docx->paddleocr) (5.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->paddleocr) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->paddleocr) (2.2.1)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->paddleocr) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\jjm98\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx->paddlepaddle) (1.2.0)\n",
      "Downloading torchaudio-2.3.1-cp310-cp310-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio matplotlib Pillow scikit-learn paddlepaddle paddleocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5be9bb9-deb6-49ed-a351-7711f30812d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from paddleocr import PaddleOCR, draw_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d8ea06-392c-4726-a3ec-5faee3deaebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/09/23 21:22:53] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\jjm98/.paddleocr/whl\\\\det\\\\ml\\\\Multilingual_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\jjm98/.paddleocr/whl\\\\rec\\\\korean\\\\korean_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Users\\\\jjm98\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\dict\\\\korean_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\jjm98/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='korean', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "# PaddleOCR 초기화\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='korean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9479454e-b39c-42d9-a1c7-43b99d141989",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'C:/Users/jjm98/OneDrive/바탕 화면/Task/train'\n",
    "label_dir = 'C:/Users/jjm98/OneDrive/바탕 화면/Task/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fe5f7df-8480-4374-9805-5ce89fdb29f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]\n",
    "labels = [f for f in os.listdir(label_dir) if f.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b036869-382b-4220-9f61-5bb29cc10159",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, val_test_imgs, train_labels, val_test_labels = train_test_split(imgs, labels, test_size=0.2, random_state=2024)\n",
    "val_imgs, test_imgs, val_labels, test_labels = train_test_split(val_test_imgs, val_test_labels, test_size=0.5, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ec7513-ea76-41c6-b7e6-893e64860f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 58876 imgs\n",
      "Validation set: 7360 imgs\n",
      "Test set: 7360 imgs\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set: {len(train_imgs)} imgs\")\n",
    "print(f\"Validation set: {len(val_imgs)} imgs\")\n",
    "print(f\"Test set: {len(test_imgs)} imgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17297f2e-c6d9-4c6d-a5d1-788725032dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def owt(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    text = ''.join([line[1][0] for line in result[0]])\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebdf6aff-34d5-4ca0-a483-11b0aa4d299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPD(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, img_files, label_files, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.img_files = img_files\n",
    "        self.label_files = label_files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_files[idx]\n",
    "        label_name = self.label_files[idx]\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        label_path = os.path.join(self.label_dir, label_name)\n",
    "\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        with open(label_path, 'r', encoding='utf-8') as f:\n",
    "            label_data = json.load(f)\n",
    "            label = label_data['value']\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 100)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db984597-4ca8-45cb-85b9-dad82d45018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NPD(img_dir, label_dir, train_imgs, train_labels, transform=transform)\n",
    "val_dataset = NPD(img_dir, label_dir, val_imgs, val_labels, transform=transform)\n",
    "test_dataset = NPD(img_dir, label_dir, test_imgs, test_labels, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb5ca8e8-3643-43d0-8101-bcf0b2ea3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "119bd930-51cf-4a1d-b547-fb7ac38016f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, imgH, nc, nclass, nh):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(nc, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, (2, 1)),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, (2, 1)),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, (2, 1)),\n",
    "            nn.MaxPool2d(2, 1)\n",
    "        )\n",
    "        self.rnn = nn.LSTM(256, nh, bidirectional=True)\n",
    "        self.fc = nn.Linear(nh * 2, nclass)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cnn(x)\n",
    "        b, c, h, w = conv.size()\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        conv = conv.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1)\n",
    "        output, _ = self.rnn(conv)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a46dcac-9996-4922-8fde-333390bba88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 1\n",
    "nh = 256\n",
    "nclass = len(\"0123456789가나다라마바사아자차카타파하\") + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fc7a020-e7f2-45a9-8f37-ea227b652615",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CRNN(imgH=32, nc=nc, nclass=nclass, nh=nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "759a9f98-1d08-4055-b981-106bd868b0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (rnn): LSTM(256, 256, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가중치 초기화 추가\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "    if isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "model.apply(weights_init)\n",
    "\n",
    "# def weights_init(m):\n",
    "#     if isinstance(m, nn.Conv2d):\n",
    "#         nn.init.kaiming_normal_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             nn.init.constant_(m.bias, 0)\n",
    "#     elif isinstance(m, nn.Linear):\n",
    "#         nn.init.xavier_normal_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd26e4d8-d3f5-4bc4-945c-1eba589e6f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (rnn): LSTM(256, 256, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a30645d8-7c10-42c6-a397-c132251b400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CTCLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6484a554-aedb-4a76-9456-a24feeeabd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: nan\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for imgs, labels in train_loader:\n",
    "        if torch.isnan(imgs).any() or torch.isinf(imgs).any():\n",
    "            print(f\"NaN or Inf detected in batch! Skipping this batch.\")\n",
    "            continue  # 문제가 있는 배치는 건너뜀\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        input_lengths = torch.full(size=(outputs.size(1),), fill_value=outputs.size(0), dtype=torch.long)\n",
    "        target_lengths = torch.tensor([len(label) for label in labels])\n",
    "\n",
    "        targets = torch.tensor([ord(char) - ord('0') for label in labels for char in label])\n",
    "\n",
    "        loss = criterion(outputs, targets, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient Clipping 추가\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a644feb7-b697-451a-aad9-88ff2f913f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'crnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bc72313-4331-4d37-a6ce-f806bb4f5540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (rnn): LSTM(256, 256, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('crnn_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9b1c1ae-3fa6-4acb-8805-908140b4d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vp(img, label, prediction):\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.title(f'True: {label}, Predicted: {prediction}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, labels in test_loader:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(imgs)\n",
    "        predictions = []\n",
    "        for output in outputs:\n",
    "            prediction = \"\"\n",
    "            for char_tensor in output:\n",
    "                # 각 char_tensor에서 가장 큰 값의 인덱스를 사용\n",
    "                char_value = char_tensor.argmax(dim=-1).item()\n",
    "                prediction += chr(char_value)\n",
    "            predictions.append(prediction)\n",
    "        \n",
    "        for i in range(len(imgs)):\n",
    "            vp(imgs[i], labels[i], predictions[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
